{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import img_as_float, img_as_uint, img_as_int, img_as_ubyte\n",
    "from skimage.transform import resize\n",
    "import imutils\n",
    "from fastai.vision import *\n",
    "from skimage import measure\n",
    "from skimage import filters\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import sys\n",
    "from fastai.vision import Image\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import bisect as bi\n",
    "import IPython.display as disp\n",
    "\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/storage')\n",
    "path_lbl = path/'vocal_cords_and_rings_data/data/labels'\n",
    "path_img = path/'vocal_cords_and_rings_data/data/images'\n",
    "path_trained_model = path/'vocal_cords_and_rings_data/data/models'\n",
    "path_lbl = path_lbl.resolve()\n",
    "path_img = path_img.resolve()\n",
    "\n",
    "num_classes = 4 #everything_else, vocal_cords, tracheal_rings, bifurcation\n",
    "\n",
    "DEBUG_MODE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(path_trained_model, 'stage-2-big-0614-rn101.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(frame):\n",
    "    '''\n",
    "    All the steps, one by one:\n",
    "    \n",
    "    frame_rgb = frame[...,::-1] #convert bgr to rgb\n",
    "\n",
    "    t = Image(pil2tensor(PIL.Image.fromarray(frame_rgb).convert(\"RGB\"), np.float32).div_(255))\n",
    "    prediction = learn.predict(t)\n",
    "    p = prediction[1].squeeze() #prediction data\n",
    "\n",
    "    mask = np.array(p).astype(np.uint8)\n",
    "    '''\n",
    "    return np.array(\n",
    "        learn.predict(Image(pil2tensor(PIL.Image.fromarray(frame[...,::-1]).convert(\"RGB\"), np.float32).div_(255)))[1].squeeze()\n",
    "        ).astype(np.uint8)\n",
    "\n",
    "def unwrap_image(mask):\n",
    "    \n",
    "    ####### Find centroid of bifurcation#####\n",
    "    mask = cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "    labels = get_blobs(mask,imshow=False)\n",
    "    thresh = labels[3]\n",
    "    thresh = img_as_uint(thresh*100)\n",
    "\n",
    "    if len(np.where( thresh > 0 )[0]):\n",
    "        # calculate moments of binary image\n",
    "        M = cv2.moments(thresh)\n",
    "        # calculate x,y coordinate of center\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        cX = 125\n",
    "        cY = 150\n",
    "        \n",
    "    ###### endof find centre ############\n",
    "    \n",
    "    value = np.sqrt(((mask.shape[0]/2.0)**2.0)+((mask.shape[1]/2.0)**2.0))\n",
    "    polar_image = cv2.linearPolar(mask.astype(np.float32),(cX,cY), value, cv2.WARP_FILL_OUTLIERS).astype(np.uint8)[:,:,0]\n",
    "    \n",
    "    return polar_image\n",
    "\n",
    "def find_posterior_region(mask, prev_posterior_angles=None, posterior_region_ctr=0):\n",
    "    if len(mask.shape)>2:\n",
    "        raise Exception('Mask should be grayscale image.')\n",
    "    \n",
    "    posterior_region_ctr+=1\n",
    "    \n",
    "    # Find anterior and posterior parts of trachea\n",
    "    histogram = np.sum((mask==1).astype(np.uint8), axis=1)#row-wise sums\n",
    "    region, posterior_angle = longest_contiguous_region(histogram < 5, histogram)\n",
    "    \n",
    "    if prev_posterior_angles is not None:\n",
    "        #Average previous angles\n",
    "        prev_posterior_angles[posterior_region_ctr%len(prev_posterior_angles)]=posterior_angle\n",
    "        posterior = int(np.average(prev_posterior_angles))\n",
    "        \n",
    "        return posterior, prev_posterior_angles, posterior_region_ctr\n",
    "\n",
    "    return posterior_angle, None, None\n",
    "\n",
    "def get_posterior_corrected_frame(mask, posterior):\n",
    "    temp = mask[0:posterior,0:]\n",
    "    return np.concatenate((mask[posterior:,0:],temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker():\n",
    "    \n",
    "    def __init__(self, init_frame=None, _verbose=False):\n",
    "        self.mid_blob_tracks = []\n",
    "        self.mid_prev=[]\n",
    "        self.verbose=_verbose\n",
    "        mask_continuous=init_frame\n",
    "\n",
    "        blobs_prev = get_blobs_single_class(mask_continuous==1, label_value=255)\n",
    "        \n",
    "        self.mid_blob_tracks = []\n",
    "        for m in blobs_prev:\n",
    "            if blob_area(m[112:122:])>0:\n",
    "                M = cv2.moments((m[112:122:]>0).astype(np.uint8))\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                self.mid_blob_tracks.append([cX])\n",
    "        self.mid_blob_tracks.sort(reverse=True)\n",
    "        mid_temp = get_middle_section(blobs_prev, collapse_channels=False)\n",
    "        \n",
    "        self.mid_prev=[]\n",
    "        for mid in mid_temp:\n",
    "            if blob_area(mid)>0:\n",
    "                self.mid_prev.append(mid)\n",
    "    \n",
    "    def iterate(self, new_frame, ring_value=1):\n",
    "        img = new_frame==ring_value\n",
    "        \n",
    "        #Find all blobs in current frame\n",
    "        blobs_current = get_blobs_single_class(img, label_value=255)\n",
    "        mid_temp = get_middle_section(blobs_current, collapse_channels=False)\n",
    "        mid_new = []\n",
    "        for mid in mid_temp:\n",
    "            if blob_area(mid)>0:\n",
    "                mid_new.append(mid)\n",
    "                \n",
    "        #Correlate children to parent blobs\n",
    "        # blobs_new has the joined blobs with indices corresponding to their parents\n",
    "        blobs_new, orphans = correlate_blobs(mid_new, self.mid_prev, orphan_min_area=50)\n",
    "        if blobs_new is None:\n",
    "            if DEBUG_MODE:\n",
    "                print(\"EMPTY!!\")\n",
    "        \n",
    "        #Add orphans to blobs_prev, so they can become parents in the next iteration\n",
    "        #Note: this happens AFTER children have already found their parents\n",
    "        self.mid_prev = []\n",
    "        for blob_ in blobs_new:\n",
    "            if blob_area(blob_[0])>0:\n",
    "                self.mid_prev.append(blob_[0])\n",
    "                \n",
    "        if DEBUG_MODE:        \n",
    "            #debug check\n",
    "            for en, bl in enumerate(self.mid_prev):\n",
    "                if blob_area(bl)<1:\n",
    "                    print(\"Empty blob at mid_prev[{}]\".format(en))\n",
    "\n",
    "        orphan_imgs = [np.array(o[0]).astype(np.uint8) for o in orphans]\n",
    "        for o in orphan_imgs:\n",
    "            if blob_area(o)>0:\n",
    "                 self.mid_prev.append(o)\n",
    "        \n",
    "        for ctr,m in enumerate(blobs_new):\n",
    "            M_prev = cv2.moments((m[1]>0).astype(np.uint8))\n",
    "            cX_prev = int(M_prev[\"m10\"] / M_prev[\"m00\"])\n",
    "            last_values = [track[-1] for track in self.mid_blob_tracks]\n",
    "\n",
    "            if blob_area(m[0])>0: #non-empty child\n",
    "                M = cv2.moments((m[0]>0).astype(np.uint8))\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])        \n",
    "\n",
    "                if cX_prev not in last_values:\n",
    "                    raise Exception('Bad correlation. Parent not in list')\n",
    "\n",
    "                self.mid_blob_tracks[last_values.index(cX_prev)].append(cX)\n",
    "            else:#child is empty\n",
    "                if DEBUG_MODE: print(\"{} NO CHILD.\".format(ctr))\n",
    "                self.mid_blob_tracks[last_values.index(cX_prev)].append(None)\n",
    "                \n",
    "        #Insert at beginning (right-most blobs)\n",
    "        last_values = [track[-1] for track in self.mid_blob_tracks]\n",
    "        try:\n",
    "            start_none, end_none = get_non_None_section(last_values)\n",
    "        except Exception as e:\n",
    "            if hasattr(e, 'message'):\n",
    "                print(e.message)\n",
    "            else:\n",
    "                print(e)\n",
    "            #Return out of iterate() indicating failed tracking\n",
    "            return False\n",
    "            \n",
    "        right_orphans = sorted(get_centroid_x(o[0]) for o in orphans if get_centroid_x(o[0]) > last_values[start_none])\n",
    "\n",
    "        for cX in right_orphans:\n",
    "            last_values = [track[-1] for track in self.mid_blob_tracks]\n",
    "            for j, val in enumerate(last_values):\n",
    "                if val is not None:\n",
    "                    if j==0 and cX > self.mid_blob_tracks[j][-1]:\n",
    "                        self.mid_blob_tracks = [[cX]] + self.mid_blob_tracks\n",
    "                        break\n",
    "                    elif j!=0 and self.mid_blob_tracks[j-1][-1] is None and cX > self.mid_blob_tracks[j][-1]:\n",
    "                        self.mid_blob_tracks[j-1].append(cX)\n",
    "                    #break is intentionally outside of elif\n",
    "                    break\n",
    "        #Insert at end (left-most blobs)\n",
    "        last_values = [track[-1] for track in self.mid_blob_tracks]\n",
    "        start_none, end_none = get_non_None_section(last_values)\n",
    "        left_orphans = sorted(get_centroid_x(o[0]) for o in orphans if get_centroid_x(o[0]) < last_values[end_none])\n",
    "        left_orphans.reverse()\n",
    "\n",
    "        for cX in left_orphans:\n",
    "            last_values = [track[-1] for track in self.mid_blob_tracks]\n",
    "            for j, val in enumerate(reversed(last_values)):\n",
    "                ctr = len(last_values)-1-j\n",
    "                if val is not None:\n",
    "                    if ctr==len(last_values)-1 and cX < self.mid_blob_tracks[ctr][-1]: #i.e. last element in un-reversed last_values)\n",
    "                        self.mid_blob_tracks = self.mid_blob_tracks+[[cX]]\n",
    "                        break\n",
    "\n",
    "                    elif ctr!=len(last_values)-1 and self.mid_blob_tracks[ctr+1][-1] is None and cX < self.mid_blob_tracks[ctr][-1]:\n",
    "                        self.mid_blob_tracks[ctr+1].append(cX)\n",
    "                    #break is intentionally outside of elif\n",
    "                    break\n",
    "                    \n",
    "        #Must remove None islands before inserting a centre blob into tracks\n",
    "        last_values = [track[-1] for track in self.mid_blob_tracks] #THIS ONE IS NEW - CHECK THAT IT WORKS IF NOT REMOVE LINE\n",
    "        start_none, end_none = get_non_None_section(last_values)\n",
    "        temp_tracks=[]\n",
    "        idx_is_none = [val is None for val in [track[-1] for track in self.mid_blob_tracks][start_none: end_none+1]]\n",
    "        for j,val in enumerate(idx_is_none):\n",
    "            if val is False:\n",
    "                temp_tracks=temp_tracks+[self.mid_blob_tracks[j+start_none]]\n",
    "        self.mid_blob_tracks = self.mid_blob_tracks[:start_none]+temp_tracks+self.mid_blob_tracks[end_none+1:]\n",
    "\n",
    "        #Insert at centre (in between other blobs in frame)\n",
    "        last_values = [track[-1] for track in self.mid_blob_tracks]\n",
    "        start_none, end_none = get_non_None_section(last_values)\n",
    "        centre_orphans = sorted(get_centroid_x(o[0]) for o in orphans if get_centroid_x(o[0]) < last_values[start_none] and get_centroid_x(o[0]) > last_values[end_none])\n",
    "        \n",
    "        for cX in centre_orphans:\n",
    "            last_values = [track[-1] for track in self.mid_blob_tracks][start_none: end_none+1]\n",
    "            # Must reverse list for insort to work properly (i.e. insort requires low to hi sorted)\n",
    "            last_values.reverse()\n",
    "            bi.insort(last_values, cX)\n",
    "            last_values.reverse()\n",
    "            idx = last_values.index(cX)+start_none\n",
    "            self.mid_blob_tracks=self.mid_blob_tracks[:idx]+[[cX]]+self.mid_blob_tracks[idx:]\n",
    "            \n",
    "        if self.verbose:\n",
    "            last_values = [track[-1] for track in self.mid_blob_tracks]\n",
    "            plot_blobs_in_order([b[0] for b in blobs_new if blob_area(b[0])>0],blobs_current,last_values,plot=True)\n",
    "        \n",
    "            fig=plt.figure(figsize=(24,24))\n",
    "            columns = 3\n",
    "            rows = 1\n",
    "            \n",
    "            imgs = [intersect,img, img-intersect]\n",
    "            for i in range(1, columns*rows +1):\n",
    "                fig.add_subplot(rows, columns, i)\n",
    "                plt.imshow(imgs[i-1])\n",
    "            plt.show()\n",
    "            \n",
    "        return True #successful tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_blobs(new_blobs, prev_blobs, percent_overlap_thresh=0.75, child_area_thresh=1.5, orphan_min_area=50):\n",
    "    \"\"\"\n",
    "    Link parent blobs from prev_blobs to children blobs from new_blobs\n",
    "    constraints:\n",
    "\n",
    "    0) children can only have one parent. parents can have multiple children\n",
    "\n",
    "    1) children must have a large enough intersection with their parent\n",
    "\n",
    "    2) children must be smaller than their parents (they are allowed to be larger up to a certain threshold)\n",
    "    if a potential child has a strong correlation to a given potential parent (large intersection), it is only\n",
    "    considered a child if child_area < parent_area*thresh (where thresh is >= 1)\n",
    "    else if a potential child has a strong correlation to a given potential parent, and it doesn't meet the area criteria,\n",
    "    a new track is created for it and it is parentless (TODO: consider going \"back\" in the tree and grouping previous blobs\n",
    "    and considering them as a single blob so that the area criteria is met. rn thinking not needed)\n",
    "\n",
    "    Args:\n",
    "        new_blobs: list in which each channel is a grayscale image\n",
    "                   that contains a single blob present in current \n",
    "                   frame (see get_blobs_single_class() )\n",
    "        prev_blobs: list in which each channel is a grayscale image\n",
    "                   that contains a single blob present in previous\n",
    "                   frame (see get_blobs_single_class() )\n",
    "        percent_overlap_thresh (default: 0.75): minimum amount that\n",
    "                   child must overlap with parent to be considered\n",
    "                   a child\n",
    "        child_area_thresh (default: 1.5): child can be up to\n",
    "                   child_area_thresh times bigger than its parent\n",
    "                   to be considered a child\n",
    "        orphan_min_area (default: 50): minimum area for a parentless\n",
    "                   blob to be added to orphan list. All orphans with\n",
    "                   less than orphan_min_area will be disregarded\n",
    "                   \n",
    "    Returns:\n",
    "        family, orphans\n",
    "        \n",
    "        family: list of tuples of (child_blob, parent_blob) i.e. the\n",
    "                actual frames are tuple[0] and tuple[1]\n",
    "                If a parent has no children, entry will be (zero_arr, parent_blob)\n",
    "                len of family is num_parent_blob\n",
    "                \n",
    "        orphans: list of tuples of (orphan_blob, None) i.e. the actual\n",
    "                frame is tuple[0], and tuple[1] is None\n",
    "                len of orphans is the number of orphans in current frame\n",
    "                   \n",
    "    \"\"\"\n",
    "    parent_to_children = {} #key is the parent ID, value is the child ID\n",
    "    orphans = [] # IDs of blobs without parents\n",
    "    \n",
    "    #Make all children empty lists\n",
    "    for p in range(0, len(prev_blobs)):\n",
    "        parent_to_children[p] = [] \n",
    "    \n",
    "    #Populate parent_to_child dict (children pick their parents)\n",
    "    for c in range(0, len(new_blobs)):\n",
    "        nblob = new_blobs[c]\n",
    "   \n",
    "        max_intercept = 0\n",
    "        max_intercept_p = -1\n",
    "                        \n",
    "        for p in range(0,len(prev_blobs)):\n",
    "            pblob = prev_blobs[p]\n",
    "            intersect = cv2.bitwise_and(nblob, pblob)\n",
    "            \n",
    "            if blob_area(intersect) > max_intercept:\n",
    "                max_intercept = blob_area(intersect)\n",
    "                max_intercept_p = p\n",
    "          \n",
    "        if max_intercept > 0 and blob_area(nblob) < blob_area(prev_blobs[max_intercept_p])*child_area_thresh and max_intercept > blob_area(nblob)*0.10:\n",
    "            parent_to_children[max_intercept_p].append(c) #Huzzah! Child picked a parent\n",
    "#             print(\"nparents {} -child {} picked {} \".format(len(prev_blobs), c, max_intercept_p))\n",
    "        else: #Child has no parent\n",
    "            orphans.append(c)\n",
    "                    \n",
    "    #Join children blobs (if they belong to the same parent) to deal with blob separation\n",
    "    #and add (child,parent) tuple to a \"family\" list\n",
    "#     joined_blobs = {} # len(new_blobs) == len(prev_blobs)+len(orphans)\n",
    "    family = []\n",
    "    \n",
    "    for p in range (0, len(parent_to_children)):\n",
    "#         joined_blobs[p] = []\n",
    "        if len(parent_to_children[p])>1: #parent has more than one child\n",
    "            joined_blob = np.zeros_like(prev_blobs[0])\n",
    "            for child_blob_index in parent_to_children[p]:\n",
    "                joined_blob = cv2.bitwise_or(new_blobs[child_blob_index], joined_blob)\n",
    "#                 print(\"JOINED BLOB TYPE {}\".format(joined_blob.dtype))\n",
    "#                 print(\"joined_blobs shape: {}\".format(joined_blob.shape))\n",
    "#             joined_blobs[p].append(joined_blob)\n",
    "            family.append((joined_blob,prev_blobs[p]))\n",
    "            \n",
    "        elif len(parent_to_children[p])==1:\n",
    "            joined_blob = new_blobs[parent_to_children[p][0]]\n",
    "#             joined_blobs[p].append(joined_blob)\n",
    "            family.append((joined_blob,prev_blobs[p]))\n",
    "        else: #do nothing -> i.e. a parent that didn't have a child will die\n",
    "            family.append((np.zeros_like(prev_blobs[p]),prev_blobs[p]))\n",
    "    \n",
    "    #Add orphans to the future parents list, so they can have children\n",
    "    orphan_imgs = []\n",
    "    for o in orphans:\n",
    "        if np.count_nonzero(new_blobs[o]) > orphan_min_area:\n",
    "            orphan_imgs.append((new_blobs[o], None))\n",
    "        \n",
    "    \n",
    "    return family, orphan_imgs #joined_blobs has prev_parents+orphans number of channels, each channel being an individual blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_channels(blobs):\n",
    "    \"\"\"\n",
    "    Collapses all image channels into a single frame\n",
    "\n",
    "    Reverses get_blobs_single_class\n",
    "\n",
    "    Args:\n",
    "        blobs: multi-channel image\n",
    "    Returns:\n",
    "        all blobs in a single frame\n",
    "    \"\"\"\n",
    "    blobs_new_frame = np.zeros_like(blobs[0])\n",
    "\n",
    "    for b in blobs:\n",
    "        blobs_new_frame = np.array(blobs_new_frame) | np.array(b)\n",
    "    return blobs_new_frame\n",
    "\n",
    "def get_centroid_x(o):\n",
    "    if blob_area(o)>0:\n",
    "        M = cv2.moments((o>0).astype(np.uint8))\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        return cX\n",
    "    \n",
    "def get_non_None_section(last_values):\n",
    "    # No blobs had children. Lost tracking\n",
    "    if last_values.count(None) == len(last_values):\n",
    "        raise Exception('Error tracking. Was not able to correlate any blobs. Must reset')\n",
    "    \n",
    "    start_none = 0\n",
    "    end_none = len(last_values)-1\n",
    "    for j, val in enumerate(last_values):\n",
    "        if val is not None:\n",
    "            start_none=j\n",
    "            break\n",
    "            \n",
    "    for j, val in enumerate(reversed(last_values)):\n",
    "        ctr=len(last_values)-1-j\n",
    "        if val is not None and ctr >= start_none:\n",
    "            end_none=ctr\n",
    "            break\n",
    "    return start_none, end_none\n",
    "\n",
    "def plot_blobs_in_order(mid_blobs, blobs, last_values, plot=True):\n",
    "    if len(mid_blobs)>len(blobs):\n",
    "        print(\"Error: Mismatched midblobs len ({}) and blobs ({}).\".format(len(mid_blobs), len(blobs)))\n",
    "        return\n",
    "    if len(blobs)==0:\n",
    "        print(\"Error: No blobs found\")\n",
    "        return\n",
    "    \n",
    "    output_frame = np.zeros_like(blobs[0])\n",
    "    for mb in mid_blobs:\n",
    "        ID = last_values.index(get_centroid_x(mb))\n",
    "        for i, b in enumerate(blobs):\n",
    "            output_frame = (output_frame) | (b/np.max(b)*20).astype(np.uint8)\n",
    "            if blobs_intersect(mb,b[112:122:].astype(np.uint8)):\n",
    "                output_frame = (output_frame) | (b/np.max(b)*(ID+1)*25).astype(np.uint8)\n",
    "                del blobs[i]\n",
    "                break\n",
    "    numbers_frame = np.zeros((224,224), np.uint8)\n",
    "    \n",
    "    start_none, end_none = get_non_None_section(last_values)\n",
    "    for cX in last_values[start_none: end_none+1]:\n",
    "        cv2.putText(numbers_frame , \"{}\".format(last_values.index(cX)), (cX, 120), cv2.FONT_HERSHEY_SIMPLEX,0.3, 255, 1)\n",
    "    output_frame = (output_frame) | (numbers_frame).astype(np.uint8)\n",
    "    \n",
    "    if plot: pltimg(output_frame)\n",
    "    \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cap fps: 29.97002997002997\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('/storage/vocal_cords_and_rings_data/nbs/20181010_12y_5031752 mild subglottic stenosis uneditted.mpg')\n",
    "out = cv2.VideoWriter('/storage/vocal_cords_and_rings_data/data/videos/trachea_map_demo.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 20.0, (720,480))\n",
    "print (\"Cap fps: {}\".format(cap.get(cv2.CAP_PROP_FPS)))\n",
    "ctr = 0\n",
    "\n",
    "######PARAMS######\n",
    "#fps of the input video\n",
    "fps=30\n",
    "#start time for annotation (in seconds)\n",
    "start_time_s= 45\n",
    "#end time for annotation (in seconds)\n",
    "end_time_s = 54\n",
    "mask_timeline = []\n",
    "clean_timeline = []\n",
    "clean_flattened_timeline = []\n",
    "frame_timeline = []\n",
    "\n",
    "# debug only\n",
    "eroded_timeline = []\n",
    "###ENDOF PARAMS###\n",
    "\n",
    "\n",
    "# Icons\n",
    "larynx_icon=cv2.imread('/storage/vocal_cords_and_rings_data/nbs/icons/larynx.png')\n",
    "ring_off_icon=cv2.imread('/storage/vocal_cords_and_rings_data/nbs/icons/ring_unselected.png')\n",
    "ring_on_icon=cv2.imread('/storage/vocal_cords_and_rings_data/nbs/icons/ring_selected.png')\n",
    "dots_icon=cv2.imread('/storage/vocal_cords_and_rings_data/nbs/icons/dotdotdot.png')\n",
    "camera_icon=cv2.imread('/storage/vocal_cords_and_rings_data/nbs/icons/camera.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "#Advance to starting frame\n",
    "for i in range(0,start_time_s*fps):\n",
    "    ret, frame = cap.read()\n",
    "    ctr+=1\n",
    "for _ in range(0,72):\n",
    "    ret, frame = cap.read()\n",
    "ret, frame = cap.read() #frame is uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctr 193\n",
      "Error tracking. Was not able to correlate any blobs. Must reset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-b0b68b94abb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moverlayed_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_trachea_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrack\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid_blob_tracks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mpltimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlayed_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlayed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#Restart tracker from next frame if tracking is not successful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/vocal_cords_and_rings_data/nbs/helper_functions.py\u001b[0m in \u001b[0;36mpltimg\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \"\"\"\n\u001b[1;32m    212\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mweight_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2047\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m                         \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2049\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2050\u001b[0m                     \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \"\"\"\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mtoolbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoolbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1649\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2626\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2628\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m-> 1187\u001b[0;31m                                                                 renderer)\n\u001b[0m\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1On\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m                 \u001b[0mextent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m                 \u001b[0mticklabelBoxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2On\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mclean_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_math_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_usetex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclean_line\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 w, h, d = renderer.get_text_width_height_descent(clean_line,\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_usetex\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musetex\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \"\"\"\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_usetex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text.usetex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clear_output()\n",
    "print (\"Starting!\")\n",
    "\n",
    "#For finding posterior region\n",
    "posterior_region_ctr = 0\n",
    "prev_posterior_angles = [int(224/4),int(224/4),int(224/4),int(224/4)]\n",
    "#endof For finding posterior region\n",
    "\n",
    "\n",
    "#For tracking\n",
    "tracker=None\n",
    "#endof For tracking\n",
    "ctr=0\n",
    "while(cap.isOpened() and ctr <end_time_s*fps):\n",
    "\n",
    "    ctr+=1\n",
    "    \n",
    "#     for i in range(0,3):\n",
    "    ret, frame = cap.read() #frame is uint8\n",
    "    if np.shape(frame) == (): #i.e. empty frame\n",
    "        break\n",
    "    \n",
    "    # Perform inference\n",
    "    mask = inference(frame)\n",
    "\n",
    "    # Convert from linear to polar\n",
    "    polar_image = unwrap_image(mask)\n",
    "\n",
    "    # Clean up linear image\n",
    "    clean_img = cv2.erode(polar_image,np.ones((11,1)))\n",
    "#     clean_flattened_timeline.append((clean_img,(cX,cY)))\n",
    "    \n",
    "    #Finding posterior region\n",
    "    posterior, prev_posterior_angles, posterior_region_ctr = find_posterior_region(clean_img, prev_posterior_angles, posterior_region_ctr)\n",
    "    mask_continuous = get_posterior_corrected_frame(clean_img, posterior)\n",
    "    \n",
    "    #Tracking\n",
    "    clear_output(wait=True)\n",
    "    print(\"ctr {}\".format(ctr))\n",
    "    \n",
    "    img = mask_continuous==1\n",
    "    if tracker is None:\n",
    "        tracker=Tracker(init_frame=img, _verbose=False)\n",
    "    else:\n",
    "        success = tracker.iterate(img)\n",
    "        overlayed_map = draw_trachea_map(frame, [track[-1] for track in tracker.mid_blob_tracks], success)\n",
    "        pltimg(overlayed_map[...,::-1])\n",
    "        out.write(overlayed_map)\n",
    "        #Restart tracker from next frame if tracking is not successful\n",
    "        if not success: tracker = None\n",
    "\n",
    "    if DEBUG_MODE:\n",
    "        #Tests for optimal erosion level\n",
    "        e_list = []\n",
    "        for num in range(5,12):\n",
    "            e = cv2.erode(polar_image,np.ones((num,1)))\n",
    "            e_list.append(e)\n",
    "        eroded_timeline.append(e_list)\n",
    "        \n",
    "        # Cleaned up linear image\n",
    "        linear_image = cv2.linearPolar(e,(cX,cY), value, cv2.WARP_INVERSE_MAP+cv2.WARP_FILL_OUTLIERS)\n",
    "        clean_timeline.append(linear_image)\n",
    "    \n",
    "cap.release()\n",
    "print (\"End!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing dynamic trachea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_transparent(new_img, transparent_img, x_offset, y_offset):\n",
    "    alpha_s = transparent_img[:, :, 3] / 255.0\n",
    "    alpha_l = 1.0 - alpha_s\n",
    "\n",
    "    for c in range(0, 3):\n",
    "        new_img[y_offset:y_offset+transparent_img.shape[0], x_offset:x_offset+transparent_img.shape[1], c] = (alpha_s * transparent_img[:, :, c] + alpha_l * new_img[y_offset:y_offset+transparent_img.shape[0], x_offset:x_offset+transparent_img.shape[1], c])\n",
    "    \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_values=[None,None,None,4,4,4,41,3,2,6,None] #debug only\n",
    "\n",
    "def draw_trachea_map(new_img, last_values, tracking_status):\n",
    "       \n",
    "    if not new_img.shape[1]>larynx_icon.shape[1]:\n",
    "        print(\"image is not wide enough\")\n",
    "    \n",
    "    y_offset=0\n",
    "    x_offset=0\n",
    "\n",
    "    #Add larynx\n",
    "    new_img[y_offset:y_offset+larynx_icon.shape[0], x_offset:x_offset+larynx_icon.shape[1]]=larynx_icon\n",
    "    y_offset+=larynx_icon.shape[0]-2\n",
    "    x_offset = abs(round((icons[0].shape[1]-icons[1].shape[1])/2)) #compensate for rings being less wide than larynx icon\n",
    "    \n",
    "    first_visible_ring=None\n",
    "    for ring_num, val in enumerate(last_values):\n",
    "        if val is None or not tracking_status:\n",
    "            new_img[y_offset:y_offset+icon.shape[0], x_offset:x_offset+icon.shape[1]] = ring_off_icon\n",
    "        else:\n",
    "            new_img[y_offset:y_offset+icon.shape[0], x_offset:x_offset+icon.shape[1]] = ring_on_icon\n",
    "            if first_visible_ring is None:\n",
    "                first_visible_ring=ring_num+1\n",
    "    \n",
    "        cv2.putText(new_img,\"{}\".format(ring_num+1),(ring_on_icon.shape[1]+10,y_offset+15),cv2.FONT_HERSHEY_SIMPLEX,0.3,(0,255,0),1)\n",
    "        y_offset+=icon.shape[0]\n",
    "    \n",
    "    if not tracking_status:\n",
    "#         cv2.putText(new_img,\"TRACKING FAILED.\",(0,y_offset+20),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),2)\n",
    "        return new_img\n",
    "        \n",
    "    # Ellipsis\n",
    "    x_offset=round(ring_on_icon.shape[1]/2)+3\n",
    "    y_offset+=2\n",
    "    new_img[y_offset:y_offset+dots_icon.shape[0], x_offset:x_offset+dots_icon.shape[1]] = dots_icon\n",
    "    \n",
    "    # Camera\n",
    "    x_offset=round(ring_on_icon.shape[1]/2)+2\n",
    "    y_offset=(first_visible_ring-1)*ring_on_icon.shape[0]+larynx_icon.shape[0]-15\n",
    "    new_img = overlay_transparent(new_img, camera_icon, x_offset, y_offset)\n",
    "        \n",
    "    return new_img\n",
    "    \n",
    "# new_img = np.zeros((300,224, 3),dtype=np.uint8) #placeholder, use video frame for actual version\n",
    "# new_img = draw_trachea_map(new_img, last_values, False)\n",
    "# pltimg(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
